{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e36b49",
   "metadata": {},
   "source": [
    "# Compare NTTT vs SAM3 Metrics\n",
    "\n",
    "This notebook loads saved prediction JSON files for NTTT and SAM3, then computes COCO bbox/segm metrics on the same ground-truth annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c46ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths to your run directory\n",
    "GT_JSON = Path('../data/olive_diseases/annotations/instances_val2017.json')\n",
    "NTTT_PRED_JSON = Path('../work_dirs/olive_nttt_sam3_eval/dinov2_large_10shot_seed42/nttt_predictions.json')\n",
    "SAM3_PRED_JSON = Path('../work_dirs/olive_nttt_sam3_eval/dinov2_large_10shot_seed42/sam3_predictions.json')\n",
    "\n",
    "NTTT_RUNTIME_JSON = NTTT_PRED_JSON.parent / 'nttt_runtime.json'\n",
    "SAM3_RUNTIME_JSON = SAM3_PRED_JSON.parent / 'sam3_runtime.json'\n",
    "\n",
    "assert GT_JSON.exists(), f'Missing GT file: {GT_JSON}'\n",
    "assert NTTT_PRED_JSON.exists(), f'Missing NTTT predictions: {NTTT_PRED_JSON}'\n",
    "assert SAM3_PRED_JSON.exists(), f'Missing SAM3 predictions: {SAM3_PRED_JSON}'\n",
    "\n",
    "print('GT:', GT_JSON)\n",
    "print('NTTT predictions:', NTTT_PRED_JSON)\n",
    "print('SAM3 predictions:', SAM3_PRED_JSON)\n",
    "print('NTTT runtime file:', NTTT_RUNTIME_JSON)\n",
    "print('SAM3 runtime file:', SAM3_RUNTIME_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NTTT_PRED_JSON, 'r') as f:\n",
    "    nttt_preds = json.load(f)\n",
    "\n",
    "with open(SAM3_PRED_JSON, 'r') as f:\n",
    "    sam3_preds = json.load(f)\n",
    "\n",
    "print(f'NTTT predictions: {len(nttt_preds)}')\n",
    "print(f'SAM3 predictions: {len(sam3_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_runtime_stat(path, key):\n",
    "    if not path.exists():\n",
    "        return float('nan')\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    value = data.get(key, float('nan'))\n",
    "    if value is None:\n",
    "        return float('nan')\n",
    "    return float(value)\n",
    "\n",
    "def run_coco_eval(gt_json_path, predictions, iou_type='segm'):\n",
    "    coco_gt = COCO(str(gt_json_path))\n",
    "    if len(predictions) == 0:\n",
    "        raise ValueError('Prediction list is empty.')\n",
    "\n",
    "    coco_dt = coco_gt.loadRes(predictions)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, iou_type)\n",
    "    coco_eval.params.imgIds = sorted(coco_gt.getImgIds())\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    stats = coco_eval.stats\n",
    "    return {\n",
    "        'AP': float(stats[0]),\n",
    "        'AP50': float(stats[1]),\n",
    "        'AP75': float(stats[2]),\n",
    "        'AP_small': float(stats[3]),\n",
    "        'AP_medium': float(stats[4]),\n",
    "        'AP_large': float(stats[5]),\n",
    "        'AR@1': float(stats[6]),\n",
    "        'AR@10': float(stats[7]),\n",
    "        'AR@100': float(stats[8]),\n",
    "        'AR_small': float(stats[9]),\n",
    "        'AR_medium': float(stats[10]),\n",
    "        'AR_large': float(stats[11]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ae590",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "runtime_files = {\n",
    "    'NTTT': NTTT_RUNTIME_JSON,\n",
    "    'SAM3': SAM3_RUNTIME_JSON,\n",
    "}\n",
    "\n",
    "for model_name, preds in [('NTTT', nttt_preds), ('SAM3', sam3_preds)]:\n",
    "    print(f'\\n===== {model_name} | BBOX =====')\n",
    "    bbox_stats = run_coco_eval(GT_JSON, preds, iou_type='bbox')\n",
    "\n",
    "    print(f'\\n===== {model_name} | SEGM =====')\n",
    "    segm_stats = run_coco_eval(GT_JSON, preds, iou_type='segm')\n",
    "\n",
    "    runtime_path = runtime_files[model_name]\n",
    "    row = {\n",
    "        'model': model_name,\n",
    "        'fps': load_runtime_stat(runtime_path, 'fps'),\n",
    "        'peak_vram_mib': load_runtime_stat(runtime_path, 'peak_vram_mib'),\n",
    "    }\n",
    "    row.update({f'bbox_{k}': v for k, v in bbox_stats.items()})\n",
    "    row.update({f'segm_{k}': v for k, v in segm_stats.items()})\n",
    "    rows.append(row)\n",
    "\n",
    "metrics_df = pd.DataFrame(rows).set_index('model')\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    'fps', 'peak_vram_mib',\n",
    "    'bbox_AP', 'bbox_AP50', 'bbox_AP75',\n",
    "    'segm_AP', 'segm_AP50', 'segm_AP75'\n",
    "]\n",
    "metrics_df[display_cols].sort_values('segm_AP', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
